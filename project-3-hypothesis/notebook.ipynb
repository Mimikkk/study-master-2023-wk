{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.utils import save_image\n",
    "from tqdm.notebook import tqdm\n",
    "from dataset import Dataset\n",
    "from configuration import config\n",
    "\n",
    "batch_size = config.dataloader.batch_size\n",
    "ds = Dataset.load(**config.dataset)\n",
    "dataloader = ds.dataloader(**config.dataloader, type='train')\n",
    "\n",
    "def denormalize(images):\n",
    "  return images * 0.5 + 0.5\n",
    "\n",
    "def show_images(images):\n",
    "  figure, ax = plt.subplots(figsize=(8, 8))\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])\n",
    "\n",
    "  ax.imshow(make_grid(images, nrow=8).permute(1, 2, 0))\n",
    "\n",
    "def show_batch(dataloader):\n",
    "  for (images, _) in dataloader:\n",
    "    images = images.detach()[:64]\n",
    "\n",
    "    show_images(denormalize(images))\n",
    "    break\n",
    "\n",
    "show_batch(dataloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from discriminator import Discriminator\n",
    "from generator import Generator\n",
    "from weights import initialize_weights\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "discriminator = Discriminator(use_gpu=config.use_gpu, scale=64).apply(initialize_weights).to(device)\n",
    "generator = Generator(use_gpu=config.use_gpu, scale=64).apply(initialize_weights).to(device)\n",
    "\n",
    "latent_size = 128\n",
    "noises = torch.randn(batch_size, latent_size, 1, 1).to(device)\n",
    "noise_images = generator(noises)\n",
    "\n",
    "show_images(noise_images.cpu())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.nn import BCELoss\n",
    "def save_samples(index, noises, show=True):\n",
    "  images = generator(noises)\n",
    "\n",
    "  filename = f'output-images-{index:0=4d}.png'\n",
    "  save_image(denormalize(images), os.path.join(output_directory, filename), nrow=8)\n",
    "  print(f'Saving {filename}')\n",
    "\n",
    "  if show:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.imshow(make_grid(images.cpu().detach(), nrow=8).permute(1, 2, 0))\n",
    "\n",
    "criterion = BCELoss()\n",
    "\n",
    "def train_discriminator(images, optimizer):\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  images_predictions = discriminator(images)\n",
    "  images_targets = torch.ones(images.size(0), 1, device=device)\n",
    "  images_targets = images_targets * 0.9\n",
    "\n",
    "  images_loss = criterion(images_predictions, images_targets)\n",
    "  images_score = torch.mean(images_predictions).item()\n",
    "\n",
    "  noises = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
    "  noises_images = generator(noises)\n",
    "\n",
    "  noises_targets = torch.zeros(noises_images.size(0), 1, device=device)\n",
    "  noises_targets = noises_targets + 0.1\n",
    "\n",
    "  noises_predictions = discriminator(noises_images)\n",
    "  noises_loss = criterion(noises_predictions, noises_targets)\n",
    "  noises_score = torch.mean(noises_predictions).item()\n",
    "\n",
    "  loss = images_loss + noises_loss\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  return loss.item(), images_score, noises_score\n",
    "\n",
    "def train_generator(optimizer):\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  noises = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
    "  noises_images = generator(noises)\n",
    "\n",
    "  predictions = discriminator(noises_images)\n",
    "  targets = torch.ones(batch_size, 1, device=device)\n",
    "  loss = criterion(predictions, targets)\n",
    "\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  return loss.item()\n",
    "\n",
    "def fit(discriminator, generator, dataloader, epochs, learning_rate):\n",
    "  torch.cuda.empty_cache()\n",
    "\n",
    "  losses_generator = []\n",
    "  losses_discriminator = []\n",
    "  images_scores = []\n",
    "  noises_scores = []\n",
    "  fid_scores = []\n",
    "\n",
    "  optimizer_discriminator = torch.optim.AdamW(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "  optimizer_generator = torch.optim.AdamW(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    for images, _ in tqdm(dataloader):\n",
    "      images = images.to(device)\n",
    "\n",
    "      loss_discriminator, images_score, noises_score = train_discriminator(images, optimizer_discriminator)\n",
    "      loss_generator = train_generator(optimizer_generator)\n",
    "\n",
    "    losses_generator.append(loss_generator)\n",
    "    losses_discriminator.append(loss_discriminator)\n",
    "\n",
    "    images_fid = images[:8].type(torch.uint8).cpu()\n",
    "    noises_fid = generator(noises[:8]).type(torch.uint8).cpu()\n",
    "    fid = FrechetInceptionDistance(feature=2048)\n",
    "    fid.update(images_fid, real=True)\n",
    "    fid.update(noises_fid, real=False)\n",
    "    fid_score = fid.compute()\n",
    "\n",
    "    fid_scores.append(fid_score)\n",
    "    images_scores.append(images_score)\n",
    "    noises_scores.append(noises_score)\n",
    "\n",
    "    print(\n",
    "      f\"Epoch [{epoch + 1}/{epochs}]\"\n",
    "      f\" loss_generator: {loss_generator:.4f}\"\n",
    "      f\" loss_discriminator: {loss_discriminator:.4f}\"\n",
    "      f\" images_score: {images_score:.4f}\"\n",
    "      f\" noises_score: {noises_score:.4f}\"\n",
    "      f\" fid_score: {fid_score:.4f}\"\n",
    "    )\n",
    "\n",
    "    save_samples(epoch, constant_noise, show=False)\n",
    "\n",
    "  return losses_generator, losses_discriminator, images_scores, noises_scores, fid_scores\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.nn.functional import adaptive_avg_pool2d\n",
    "from numpy.linalg import linalg\n",
    "import numpy as np\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scales = [256]\n",
    "learning_rate = 0.0002\n",
    "epochs = 200\n",
    "\n",
    "for generator_scale in scales:\n",
    "\n",
    "  for discriminator_scale in scales:\n",
    "    generator = (\n",
    "      Generator(use_gpu=config.use_gpu, scale=generator_scale)\n",
    "      .apply(initialize_weights)\n",
    "      .to(device)\n",
    "    )\n",
    "    discriminator = (\n",
    "      Discriminator(use_gpu=config.use_gpu, scale=discriminator_scale)\n",
    "      .apply(initialize_weights)\n",
    "      .to(device)\n",
    "    )\n",
    "\n",
    "    output_directory = f'results/{generator_scale}-{discriminator_scale}'\n",
    "    model_directory = f'models/{generator_scale}-{discriminator_scale}'\n",
    "\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    os.makedirs(model_directory, exist_ok=True)\n",
    "\n",
    "    constant_noise = torch.randn(64, latent_size, 1, 1, device=device)\n",
    "    save_samples(0, constant_noise)\n",
    "\n",
    "    (\n",
    "      losses_generator,\n",
    "      losses_discriminator,\n",
    "      images_scores,\n",
    "      noises_scores,\n",
    "      fid_scores\n",
    "    ) = fit(\n",
    "      discriminator,\n",
    "      generator,\n",
    "      dataloader,\n",
    "      epochs=epochs,\n",
    "      learning_rate=learning_rate\n",
    "    )\n",
    "\n",
    "    torch.save(generator.state_dict(), f'{model_directory}-generator.pt')\n",
    "    torch.save(discriminator.state_dict(), f'{model_directory}-discriminator.pt')\n",
    "\n",
    "    scores_directory = f'scores/{generator_scale}-{discriminator_scale}'\n",
    "    os.makedirs(scores_directory, exist_ok=True)\n",
    "    csv = open(f'{scores_directory}.csv', 'w')\n",
    "    csv.write('loss_generator,loss_discriminator,images_score,noises_score,fid_score\\n')\n",
    "    for epoch in range(epochs):\n",
    "      csv.write(\n",
    "        f'{losses_generator[epoch]},{losses_discriminator[epoch]},{images_scores[epoch]},{noises_scores[epoch]},{fid_scores[epoch]}\\n')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
