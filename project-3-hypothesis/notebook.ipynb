{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.utils import save_image\n",
    "from tqdm.notebook import tqdm\n",
    "from dataset import Dataset\n",
    "from configuration import config\n",
    "\n",
    "batch_size = config.dataloader.batch_size\n",
    "ds = Dataset.load(**config.dataset)\n",
    "dataloader = ds.dataloader(**config.dataloader, type='train')\n",
    "\n",
    "def denormalize(images):\n",
    "  return images * 0.5 + 0.5\n",
    "\n",
    "def show_images(images):\n",
    "  fig, ax = plt.subplots(figsize=(8, 8))\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])\n",
    "\n",
    "  ax.imshow(make_grid(denormalize(images.detach()[:64]), nrow=8).permute(1, 2, 0))\n",
    "\n",
    "def show_batch(dataloader):\n",
    "  for (images, _) in dataloader:\n",
    "    print(images.shape)\n",
    "    show_images(images)\n",
    "    break\n",
    "\n",
    "show_batch(dataloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from discriminator import Discriminator\n",
    "from generator import Generator\n",
    "from weights import initialize_weights\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "discriminator = Discriminator(use_gpu=config.use_gpu).apply(initialize_weights).to(device)\n",
    "generator = Generator(use_gpu=config.use_gpu).apply(initialize_weights).to(device)\n",
    "\n",
    "latent_size = 128\n",
    "noises = torch.randn(batch_size, latent_size, 1, 1).to(device)\n",
    "noise_images = generator(noises)\n",
    "\n",
    "show_images(noise_images.cpu())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_discriminator(images, optimizer):\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  images_predictions = discriminator(images)\n",
    "  images_targets = torch.ones(images.size(0), 1, device=device)\n",
    "  images_loss = F.binary_cross_entropy(images_predictions, images_targets)\n",
    "  images_score = torch.mean(images_predictions).item()\n",
    "\n",
    "  noises = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
    "  noises_images = generator(noises)\n",
    "\n",
    "  noises_targets = torch.zeros(noises_images.size(0), 1, device=device)\n",
    "  noises_predictions = discriminator(noises_images)\n",
    "  noises_loss = F.binary_cross_entropy(noises_predictions, noises_targets)\n",
    "  noises_score = torch.mean(noises_predictions).item()\n",
    "\n",
    "  loss = images_loss + noises_loss\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  return loss.item(), images_score, noises_score\n",
    "\n",
    "def train_generator(optimizer):\n",
    "  optimizer.zero_grad()\n",
    "\n",
    "  noises = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
    "  noises_images = generator(noises)\n",
    "\n",
    "  predictions = discriminator(noises_images)\n",
    "  targets = torch.ones(batch_size, 1, device=device)\n",
    "  loss = F.binary_cross_entropy(predictions, targets)\n",
    "\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  return loss.item()\n",
    "\n",
    "def save_samples(index, latent_tensors, show=True):\n",
    "  noise_images = generator(latent_tensors)\n",
    "  noise_filename = f'generated-images-{index:0=4d}.png'\n",
    "\n",
    "  save_image(denormalize(noise_images), os.path.join(sluts_directory, noise_filename), nrow=8)\n",
    "  print(f'Saving {noise_filename}')\n",
    "\n",
    "  if show:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.set_xticks([]);\n",
    "    ax.set_yticks([])\n",
    "    ax.imshow(make_grid(noise_images.cpu().detach(), nrow=8).permute(1, 2, 0))\n",
    "\n",
    "def fit(discriminator, generator, dataloader, epochs, learning_rate):\n",
    "  torch.cuda.empty_cache()\n",
    "\n",
    "  losses_generator = []\n",
    "  losses_discriminator = []\n",
    "  images_scores = []\n",
    "  noises_scores = []\n",
    "\n",
    "  optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "  optimizer_generator = torch.optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    for images_images, _ in tqdm(dataloader):\n",
    "      images_images = images_images.to(device)\n",
    "\n",
    "      loss_discriminator, images_score, noises_score = train_discriminator(images_images, optimizer_discriminator)\n",
    "      loss_generator = train_generator(optimizer_generator)\n",
    "\n",
    "    losses_generator.append(loss_generator)\n",
    "    losses_discriminator.append(loss_discriminator)\n",
    "    images_scores.append(images_score)\n",
    "    noises_scores.append(noises_score)\n",
    "\n",
    "    print(\n",
    "      f\"Epoch [{epoch + 1}/{epochs}]\"\n",
    "      f\" loss_generator: {loss_generator:.4f}\"\n",
    "      f\" loss_discriminator: {loss_discriminator:.4f}\"\n",
    "      f\" images_score: {images_score:.4f}\"\n",
    "      f\" noises_score: {noises_score:.4f}\"\n",
    "    )\n",
    "\n",
    "    save_samples(epoch, constant_noise, show=False)\n",
    "\n",
    "  return losses_generator, losses_discriminator, images_scores, noises_scores\n",
    "learning_rate = 0.0002\n",
    "epochs = 600\n",
    "\n",
    "sluts_directory = 'generated'\n",
    "os.makedirs(sluts_directory, exist_ok=True)\n",
    "constant_noise = torch.randn(64, latent_size, 1, 1, device=device)\n",
    "save_samples(0, constant_noise)\n",
    "\n",
    "history = fit(\n",
    "  discriminator,\n",
    "  generator,\n",
    "  dataloader,\n",
    "  epochs=epochs,\n",
    "  learning_rate=learning_rate\n",
    ")\n",
    "losses_generator, losses_discriminator, image_scores, noise_scores = history\n",
    "from IPython.display import Image\n",
    "Image('./generated/generated-images-00600.png')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "video_filename = 'gans_training.avi'\n",
    "\n",
    "files = [os.path.join(sluts_directory, file) for file in os.listdir(sluts_directory) if 'generated' in file]\n",
    "files.sort()\n",
    "\n",
    "video = cv2.VideoWriter(video_filename, cv2.VideoWriter_fourcc(*'MP4V'), 1, (530, 530))\n",
    "for filename in files: video.write(cv2.imread(filename))\n",
    "video.release()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
